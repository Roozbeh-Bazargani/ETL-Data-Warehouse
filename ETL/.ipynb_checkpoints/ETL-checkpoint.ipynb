{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import psycopg2.extras\n",
    "from optparse import OptionParser, OptionGroup\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to an existing database\n",
    "conn1 = psycopg2.connect(\"dbname=DB-project user=postgres password=admin\")\n",
    "conn2 = psycopg2.connect(\"dbname=DB-project-ETL user=postgres password=admin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur1 = conn1.cursor()\n",
    "cur2 = conn2.cursor()\n",
    "\n",
    "conn1.autocommit = True\n",
    "conn2.autocommit = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pk(cursor, table):\n",
    "    cursor.execute(\"\"\"\n",
    "    SELECT c.column_name, c.data_type\n",
    "    FROM information_schema.table_constraints tc \n",
    "    JOIN information_schema.constraint_column_usage AS ccu USING (constraint_schema, constraint_name) \n",
    "    JOIN information_schema.columns AS c ON c.table_schema = tc.constraint_schema\n",
    "      AND tc.table_name = c.table_name AND ccu.column_name = c.column_name\n",
    "    WHERE constraint_type = 'PRIMARY KEY' and tc.table_name = '{table}';\n",
    "    \"\"\".format(table=table))\n",
    "\n",
    "def extract_pk_values(cursor, table, pk):\n",
    "    cursor.execute(\"\"\"\n",
    "    SELECT {pk}\n",
    "    FROM {table}\n",
    "    \"\"\".format(table=table, pk=pk))\n",
    "    \n",
    "def table_allrows(cursor, table):\n",
    "    cursor.execute(\"\"\"\n",
    "    SELECT *\n",
    "    FROM {table};\n",
    "    \"\"\".format(table=table))\n",
    "\n",
    "def insert_warehouse(cursor, value, table, pk, pk_value):\n",
    "    cursor.execute(\"\"\"\n",
    "    DELETE FROM {table}\n",
    "    WHERE {pk}={pk_value};\n",
    "    INSERT INTO {table}\n",
    "    VALUES {value}\n",
    "    \"\"\".format(table=table, value=value, pk=pk, pk_value=pk_value))\n",
    "    \n",
    "def delete_warehouse(cursor, table, pk, pk_values):\n",
    "    cursor.execute(\"\"\"\n",
    "    DELETE FROM {table}\n",
    "    WHERE {pk} NOT IN {pk_values}\n",
    "    \"\"\".format(table=table, pk=pk, pk_values=pk_values))\n",
    "    \n",
    "def record_value(records):\n",
    "    pk_value = records[0]\n",
    "    if type(pk_value) == str:\n",
    "        pk_value = \"'\" + pk_value + \"'\"\n",
    "    value = '(' + str(pk_value)\n",
    "    for record in records[1:]:\n",
    "        if record == None:\n",
    "            record = 'NULL'\n",
    "        elif type(record) != int:\n",
    "            record = \"'{}'\".format(record)\n",
    "        value += ', ' + str(record)\n",
    "    value += ')'\n",
    "    if len(records) == 1:\n",
    "        value = value[:-1] + ')'\n",
    "    return pk_value, value\n",
    "\n",
    "def key_pk_values(keys):\n",
    "    pk_values = '('\n",
    "    for key in keys:\n",
    "        if type(key[0]) == str:\n",
    "            pk_values += \"'{}', \".format(key[0])\n",
    "        else:\n",
    "            pk_values += '{}, '.format(key[0])\n",
    "    pk_values = pk_values[:-2]\n",
    "    pk_values +=')'\n",
    "    return pk_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(table):\n",
    "    # insert and update \n",
    "    with conn1.cursor() as cursor1:\n",
    "        table_allrows(cursor1, table)\n",
    "        records = cursor1.fetchone()\n",
    "#         print(str(records[1]))\n",
    "        with conn2.cursor() as cursor2:\n",
    "            extract_pk(cursor2, table)\n",
    "            pk = cursor2.fetchone()[0]\n",
    "        while records != None:\n",
    "            pk_value, value = record_value(records)\n",
    "#             print(value)\n",
    "            with conn2.cursor() as cursor2:\n",
    "                try:\n",
    "                    insert_warehouse(cursor2, value, table, pk, pk_value)\n",
    "                    conn2.commit()\n",
    "                except Exception as e:\n",
    "                    conn2.rollback()\n",
    "                    raise\n",
    "            records = cursor1.fetchone()\n",
    "    # delete\n",
    "    with conn1.cursor() as cursor1:\n",
    "        extract_pk_values(cursor1, table, pk)\n",
    "        keys = cursor1.fetchall()\n",
    "        pk_values = key_pk_values(keys)\n",
    "        if pk_values==' ) ': # No data in the table\n",
    "            with conn2.cursor() as cursor2:\n",
    "                delete_warehouse(cursor2, table, pk, pk_values)\n",
    "                conn2.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline('languageb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# type(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writedeps(cursor, tbl, dependency):\n",
    "    sql = \"\"\"SELECT\n",
    "        tc.constraint_name, tc.table_name, kcu.column_name,\n",
    "        ccu.table_name AS foreign_table_name,\n",
    "        ccu.column_name AS foreign_column_name\n",
    "    FROM\n",
    "        information_schema.table_constraints AS tc\n",
    "    JOIN information_schema.key_column_usage AS kcu ON\n",
    "        tc.constraint_name = kcu.constraint_name\n",
    "    JOIN information_schema.constraint_column_usage AS ccu ON\n",
    "        ccu.constraint_name = tc.constraint_name\n",
    "    WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = '%s'\"\"\"\n",
    "    cursor.execute(sql % tbl)\n",
    "    for row in cursor.fetchall():\n",
    "        constraint, table, column, foreign_table, foreign_column = row\n",
    "        print('{} -> {} [label={}];'.format(tbl, foreign_table, constraint))\n",
    "        dependency.append([tbl, foreign_table])\n",
    "    return dependency\n",
    "\n",
    "\n",
    "def get_tables(cursor):\n",
    "    cursor.execute(\"SELECT tablename FROM pg_tables WHERE schemaname='public'\")\n",
    "    for row in cursor.fetchall():\n",
    "        yield row[0]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Digraph F {\n",
      "\n",
      "ranksep=1.0; size=\"18.5, 15.5\"; rankdir=LR;\n",
      "book -> person [label=book_main_author_fkey];\n",
      "book -> languageb [label=book_main_language_fkey];\n",
      "book -> genre [label=book_main_genre_fkey];\n",
      "user_library -> person [label=user_library_person_id_fkey];\n",
      "written_by -> person [label=written_by_person_id_fkey];\n",
      "written_by -> book [label=written_by_book_id_fkey];\n",
      "translated_by -> person [label=translated_by_person_id_fkey];\n",
      "translated_by -> book [label=translated_by_book_id_fkey];\n",
      "language_book -> languageb [label=language_book_languageb_fkey];\n",
      "language_book -> book [label=language_book_book_id_fkey];\n",
      "genre_book -> genre [label=genre_book_genre_fkey];\n",
      "genre_book -> book [label=genre_book_book_id_fkey];\n",
      "borrowed -> user_library [label=borrowed_user_id_fkey];\n",
      "borrowed -> book [label=borrowed_book_id_fkey];\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"Digraph F {\\n\")\n",
    "print('ranksep=1.0; size=\"18.5, 15.5\"; rankdir=LR;')\n",
    "dependency = []\n",
    "with conn1.cursor() as cursor1:\n",
    "    for i in get_tables(cursor1):\n",
    "        dependency = writedeps(cursor1, i, dependency)\n",
    "    print(\"}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['book', 'person'], ['book', 'languageb'], ['book', 'genre'], ['user_library', 'person'], ['written_by', 'person'], ['written_by', 'book'], ['translated_by', 'person'], ['translated_by', 'book'], ['language_book', 'languageb'], ['language_book', 'book'], ['genre_book', 'genre'], ['genre_book', 'book'], ['borrowed', 'user_library'], ['borrowed', 'book']]\n"
     ]
    }
   ],
   "source": [
    "print(dependency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topological sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list of tables:\n",
      " ['person', 'book', 'languageb', 'genre', 'user_library', 'written_by', 'translated_by', 'language_book', 'genre_book', 'borrowed']\n"
     ]
    }
   ],
   "source": [
    "def tables(cursor):\n",
    "    cursor.execute(\"SELECT tablename FROM pg_tables WHERE schemaname='public'\")\n",
    "    tables = []\n",
    "    for row in cursor.fetchall():\n",
    "        tables.append(row[0])\n",
    "    return tables\n",
    "\n",
    "with conn1.cursor() as cursor1:\n",
    "    tables = tables(cursor1)\n",
    "    print('list of tables:\\n', tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(tables.index('book'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Following is a Topological Sort of the given graph\n",
      "[0, 2, 3, 1, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "#Python program to print topological sorting of a DAG\n",
    "from collections import defaultdict\n",
    "\n",
    "#Class to represent a graph\n",
    "class Graph:\n",
    "    def __init__(self,vertices):\n",
    "        self.graph = defaultdict(list) #dictionary containing adjacency List\n",
    "        self.V = vertices #No. of vertices\n",
    "\n",
    "    # function to add an edge to graph\n",
    "    def addEdge(self,u,v):\n",
    "        self.graph[u].append(v)\n",
    "\n",
    "    # A recursive function used by topologicalSort\n",
    "    def topologicalSortUtil(self,v,visited,stack):\n",
    "\n",
    "        # Mark the current node as visited.\n",
    "        visited[v] = True\n",
    "\n",
    "        # Recur for all the vertices adjacent to this vertex\n",
    "        for i in self.graph[v]:\n",
    "            if visited[i] == False:\n",
    "                self.topologicalSortUtil(i,visited,stack)\n",
    "\n",
    "        # Push current vertex to stack which stores result\n",
    "        stack.insert(0,v)\n",
    "\n",
    "    # The function to do Topological Sort. It uses recursive\n",
    "    # topologicalSortUtil()\n",
    "    def topologicalSort(self):\n",
    "        # Mark all the vertices as not visited\n",
    "        visited = [False]*self.V\n",
    "        stack =[]\n",
    "\n",
    "        # Call the recursive helper function to store Topological\n",
    "        # Sort starting from all vertices one by one\n",
    "        for i in range(self.V):\n",
    "            if visited[i] == False:\n",
    "                self.topologicalSortUtil(i,visited,stack)\n",
    "\n",
    "        # Print contents of stack\n",
    "        stack = stack[::-1]\n",
    "        print(stack)\n",
    "        return stack\n",
    "\n",
    "g= Graph(len(tables))\n",
    "for dep in dependency:\n",
    "    g.addEdge(tables.index(dep[0]), tables.index(dep[1]))\n",
    "\n",
    "print(\"Following is a Topological Sort of the given graph\")\n",
    "stack = g.topologicalSort()\n",
    "#This code is contributed by Neelam Yadav\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_to_sort_tables(stack, tables):\n",
    "    sort_table = []\n",
    "    for s in stack:\n",
    "        sort_table.append(tables[s])\n",
    "    return sort_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['person', 'languageb', 'genre', 'book', 'user_library', 'written_by', 'translated_by', 'language_book', 'genre_book', 'borrowed']\n"
     ]
    }
   ],
   "source": [
    "sort_table = stack_to_sort_tables(stack, tables)\n",
    "print(sort_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "ename": "ForeignKeyViolation",
     "evalue": "update or delete on table \"person\" violates foreign key constraint \"book_main_author_fkey\" on table \"book\"\nDETAIL:  Key (person_id)=(1) is still referenced from table \"book\".\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mForeignKeyViolation\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-101-7db654c2c159>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtable\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msort_table\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mpipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-98-f8d5d499af2b>\u001b[0m in \u001b[0;36mpipeline\u001b[1;34m(table)\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mconn2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcursor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcursor2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                     \u001b[0minsert_warehouse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcursor2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpk_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m                     \u001b[0mconn2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-97-d63518e3ca02>\u001b[0m in \u001b[0;36minsert_warehouse\u001b[1;34m(cursor, value, table, pk, pk_value)\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0mINSERT\u001b[0m \u001b[0mINTO\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mtable\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[0mVALUES\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m     \"\"\".format(table=table, value=value, pk=pk, pk_value=pk_value))\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdelete_warehouse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcursor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpk_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mForeignKeyViolation\u001b[0m: update or delete on table \"person\" violates foreign key constraint \"book_main_author_fkey\" on table \"book\"\nDETAIL:  Key (person_id)=(1) is still referenced from table \"book\".\n"
     ]
    }
   ],
   "source": [
    "for table in sort_table:\n",
    "    pipeline(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
