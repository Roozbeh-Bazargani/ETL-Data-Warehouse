{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import psycopg2.extras\n",
    "from optparse import OptionParser, OptionGroup\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to an existing database\n",
    "conn1 = psycopg2.connect(\"dbname=DB-project user=postgres password=admin\")\n",
    "conn2 = psycopg2.connect(\"dbname=DB-Project-ETL user=postgres password=admin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur1 = conn1.cursor()\n",
    "cur2 = conn2.cursor()\n",
    "\n",
    "conn1.autocommit = True\n",
    "conn2.autocommit = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pk(cursor, table):\n",
    "    cursor.execute(\"\"\"\n",
    "    SELECT c.column_name, c.data_type\n",
    "    FROM information_schema.table_constraints tc \n",
    "    JOIN information_schema.constraint_column_usage AS ccu USING (constraint_schema, constraint_name) \n",
    "    JOIN information_schema.columns AS c ON c.table_schema = tc.constraint_schema\n",
    "      AND tc.table_name = c.table_name AND ccu.column_name = c.column_name\n",
    "    WHERE constraint_type = 'PRIMARY KEY' and tc.table_name = '{table}';\n",
    "    \"\"\".format(table=table))\n",
    "\n",
    "def extract_pk_values(cursor, table, pk):\n",
    "    cursor.execute(\"\"\"\n",
    "    SELECT {pk}\n",
    "    FROM {table}\n",
    "    \"\"\".format(table=table, pk=pk))\n",
    "    \n",
    "def table_allrows(cursor, table):\n",
    "    cursor.execute(\"\"\"\n",
    "    SELECT *\n",
    "    FROM {table};\n",
    "    \"\"\".format(table=table))\n",
    "\n",
    "def insert_warehouse(cursor, value, table, pk, pk_value):\n",
    "    cursor.execute(\"\"\"\n",
    "    DELETE FROM {table}\n",
    "    WHERE {pk}={pk_value};\n",
    "    INSERT INTO {table}\n",
    "    VALUES {value}\n",
    "    \"\"\".format(table=table, value=value, pk=pk, pk_value=pk_value))\n",
    "    \n",
    "def delete_warehouse(cursor, table, pk, pk_values):\n",
    "    cursor.execute(\"\"\"\n",
    "    DELETE FROM {table}\n",
    "    WHERE {pk} NOT IN {pk_values}\n",
    "    \"\"\".format(table=table, pk=pk, pk_values=pk_values))\n",
    "    \n",
    "def record_value(records):\n",
    "    pk_value = records[0]\n",
    "    if type(pk_value) == str:\n",
    "        pk_value = \"'\" + pk_value + \"'\"\n",
    "    value = str(records).replace('None', \"NULL\")\n",
    "    if len(records) == 1:\n",
    "        value = value[:-2] + ')'\n",
    "    return pk_value, value\n",
    "\n",
    "def key_pk_values(keys):\n",
    "    pk_values = '('\n",
    "    for key in keys:\n",
    "        if type(key[0]) == str:\n",
    "            pk_values += \"'{}', \".format(key[0])\n",
    "        else:\n",
    "            pk_values += '{}, '.format(key[0])\n",
    "    pk_values = pk_values[:-2]\n",
    "    pk_values +=')'\n",
    "    return pk_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(table):\n",
    "    # insert and update \n",
    "    with conn1.cursor() as cursor1:\n",
    "        table_allrows(cursor1, table)\n",
    "        records = cursor1.fetchone()\n",
    "        with conn2.cursor() as cursor2:\n",
    "            extract_pk(cursor2, table)\n",
    "            pk = cursor2.fetchone()[0]\n",
    "        while records != None:\n",
    "            pk_value, value = record_value(records)\n",
    "            with conn2.cursor() as cursor2:\n",
    "                try:\n",
    "                    insert_warehouse(cursor2, value, table, pk, pk_value)\n",
    "                    conn2.commit()\n",
    "                except Exception as e:\n",
    "                    conn2.rollback()\n",
    "                    raise\n",
    "            records = cursor1.fetchone()\n",
    "    # delete\n",
    "    with conn1.cursor() as cursor1:\n",
    "        extract_pk_values(cursor1, table, pk)\n",
    "        keys = cursor1.fetchall()\n",
    "        pk_values = key_pk_values(keys)\n",
    "        with conn2.cursor() as cursor2:\n",
    "            delete_warehouse(cursor2, table, pk, pk_values)\n",
    "            conn2.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline('language_book')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writedeps(cursor, tbl):\n",
    "    sql = \"\"\"SELECT\n",
    "        tc.constraint_name, tc.table_name, kcu.column_name,\n",
    "        ccu.table_name AS foreign_table_name,\n",
    "        ccu.column_name AS foreign_column_name\n",
    "    FROM\n",
    "        information_schema.table_constraints AS tc\n",
    "    JOIN information_schema.key_column_usage AS kcu ON\n",
    "        tc.constraint_name = kcu.constraint_name\n",
    "    JOIN information_schema.constraint_column_usage AS ccu ON\n",
    "        ccu.constraint_name = tc.constraint_name\n",
    "    WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = '%s'\"\"\"\n",
    "    cursor.execute(sql % tbl)\n",
    "    for row in cursor.fetchall():\n",
    "        constraint, table, column, foreign_table, foreign_column = row\n",
    "        print('{} -> {} [label={}];'.format(tbl, foreign_table, constraint))\n",
    "\n",
    "\n",
    "def get_tables(cursor):\n",
    "    cursor.execute(\"SELECT tablename FROM pg_tables WHERE schemaname='public'\")\n",
    "    for row in cursor.fetchall():\n",
    "        yield row[0]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Digraph F {\n",
      "\n",
      "ranksep=1.0; size=\"18.5, 15.5\"; rankdir=LR;\n",
      "borrowed -> user_library [label=borrowed_user_id_fkey];\n",
      "written_by -> writer [label=written_by_writer_id_fkey];\n",
      "translated_by -> translator [label=translated_by_translator_id_fkey];\n",
      "language_book -> languageb [label=language_book_languageb_fkey];\n",
      "genre_book -> genre [label=genre_book_genre_fkey];\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"Digraph F {\\n\")\n",
    "print('ranksep=1.0; size=\"18.5, 15.5\"; rankdir=LR;')\n",
    "with conn1.cursor() as cursor1:\n",
    "    for i in get_tables(cursor1):\n",
    "        writedeps(cursor1, i)\n",
    "    print(\"}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
